import re
from urllib.parse import urlparse

# ======================================================
# 丘뒲잺 Pesos de se침ales (NO SE USAN POR AHORA, SE CONSERVAN)
# ======================================================
WEIGHTS = {
    "categorical_claim": 1.0,
    "emotional_tone": 0.8,
    "absolute_generalization": 1.0,
    "serious_accusation": 2.8,
    "conspiracy_language": 3.0,
    "no_sources_with_accusations": 2.0,
}

# ======================================================
# 游댌 Helpers
# ======================================================
def contains(patterns, text):
    return any(re.search(p, text, re.IGNORECASE) for p in patterns)

def count(patterns, text):
    return sum(len(re.findall(p, text, re.IGNORECASE)) for p in patterns)

# ======================================================
# 游깷 Tipo de sitio
# ======================================================
def detect_site_type(url: str) -> str:
    if not url:
        return "unknown"

    domain = urlparse(url).netloc.lower()

    if any(k in domain for k in [".gob.", ".gov.", ".edu.", "indec", "estadistica"]):
        return "institutional"

    if any(k in domain for k in [
        "clarin", "lanacion", "iprofesional", "infobae", "perfil",
        "ambito", "cronista", "bbc", "guardian", "reuters",
        "bloomberg", "nyt", "elpais", "lemonde", "dw", "cnn"
    ]):
        return "media"

    if any(k in domain for k in [
        "facebook", "twitter", "x.com", "instagram", "tiktok", "youtube"
    ]):
        return "social"

    return "blog"

# ======================================================
# 游 Engine principal (VERSI칍N CORRECTA)
# ======================================================
def analyze_text(text: str, page_type: str = "unknown", url: str = ""):
    risk_disinformation = 0.0
    risk_opinion = 0.0
    signals = []

    site_type = page_type if page_type != "unknown" else detect_site_type(url)

    # ===============================
    # OPINI칍N / RET칍RICA
    # ===============================
    if contains([
        r"creo que",
        r"en mi opini칩n",
        r"parece que",
        r"podr칤a ser",
        r"considero que"
    ], text):
        risk_opinion += 1.5
        signals.append("Lenguaje de opini칩n")

    if count([
        r"esc치ndalo", r"grave", r"indignante",
        r"urgente", r"alarmante", r"terrible"
    ], text) >= 2:
        risk_opinion += 1.0
        signals.append("Lenguaje emocional")

    # ===============================
    # DESINFORMACI칍N
    # ===============================
    if contains([
        r"fraude", r"estafa", r"corrupci칩n",
        r"manipulaci칩n", r"enga침o"
    ], text):
        risk_disinformation += 2.5
        signals.append("Acusaciones graves")

        if not contains([r"http", r"seg칰n", r"fuente", r"informe"], text):
            risk_disinformation += 2.0
            signals.append("Acusaciones sin fuentes")

    if contains([
        r"no quieren que sepas",
        r"te est치n ocultando",
        r"nadie habla de esto",
        r"verdad oculta"
    ], text):
        risk_disinformation += 3.0
        signals.append("Lenguaje conspirativo")

    # ===============================
    # MODULADORES POR TIPO DE SITIO
    # ===============================
    if site_type == "institutional":
        risk_disinformation *= 0.3
        risk_opinion *= 0.5

    elif site_type == "media":
        risk_disinformation *= 0.6
        risk_opinion *= 0.8

    elif site_type == "social":
        risk_disinformation *= 1.3

    # ===============================
    # DECISI칍N FINAL (TABLA)
    # ===============================
    if risk_disinformation >= 4.5:
        status = "red"
    elif risk_opinion >= 2.0:
        status = "yellow"
    else:
        status = "green"

    return {
        "status": status,
        "score": round(risk_disinformation + risk_opinion, 2),
        "signals": signals,
        "site_type": site_type,
        "risk_disinformation": round(risk_disinformation, 2),
        "risk_opinion": round(risk_opinion, 2)
    }
